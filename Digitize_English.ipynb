{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Digitize English.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ikonthomas/Digitize-Handwritten-Texts/blob/master/Digitize_English.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "GvDbTPcRmxfK",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "548b54a1-1997-40fb-b438-ed16b4b30048"
      },
      "cell_type": "code",
      "source": [
        "\n",
        "# Imports\n",
        "from __future__ import division\n",
        "import numpy as np\n",
        "import os\n",
        "import glob\n",
        "from PIL import Image\n",
        "from random import *\n",
        "from keras.utils import to_categorical\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.image as mpimg\n",
        "%matplotlib inline\n",
        "\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Flatten, Lambda, ELU, Activation, BatchNormalization\n",
        "from keras.layers.convolutional import Convolution2D, Cropping2D, ZeroPadding2D, MaxPooling2D\n",
        "from keras.optimizers import SGD, Adam, RMSprop"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "UkBWOc61mzYt",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 132
        },
        "outputId": "3eb4ce4b-9518-423b-aef0-30262b4fd4d3"
      },
      "cell_type": "code",
      "source": [
        "# Create sentence writer mapping\n",
        "#Dictionary with form and writer mapping\n",
        "d = {}\n",
        "\n",
        "#pd.read_txt('https://raw.githubusercontent.com/ikonthomas/Digitize-Handwritten-Texts/master/forms_for%20parsing.txt') as f:\n",
        "with open('forms_for_parsing.txt') as f:\n",
        "    for line in f:\n",
        "        key = line.split(' ')[0]\n",
        "        writer = line.split(' ')[1]\n",
        "        d[key] = writer"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "error",
          "ename": "SyntaxError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-6-b06754876360>\"\u001b[0;36m, line \u001b[0;32m3\u001b[0m\n\u001b[0;31m    pd.read_txt('https://raw.githubusercontent.com/ikonthomas/Digitize-Handwritten-Texts/master/forms_for%20parsing.txt') as f:\u001b[0m\n\u001b[0m                                                                                                                           ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "KZlVpjDem4Oh",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Create array of file names and corresponding target writer names\n",
        "tmp = []\n",
        "target_list = []\n",
        "path_to_files = os.path.join('data_subset', '*')\n",
        "for filename in sorted(glob.glob(path_to_files)):\n",
        "    tmp.append(filename)\n",
        "    image_name = filename.split('/')[-1]\n",
        "    file, ext = os.path.splitext(image_name)\n",
        "    parts = file.split('-')\n",
        "    form = parts[0] + '-' + parts[1]\n",
        "    for key in d:\n",
        "        if key == form:\n",
        "            target_list.append(str(d[form]))\n",
        "\n",
        "img_files = np.asarray(tmp)\n",
        "img_targets = np.asarray(target_list)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "pGIa4eG8nDwB",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Visualizing dataset\n",
        "See below data from Writer 1 - Each image is a unique sentence.\n",
        "\n",
        "<img src=\"markdown_pics/w1_s0.png\" style=\"float: left; margin-right: 10px;\" width = 800 />\n",
        "\n",
        "<img src=\"markdown_pics/w1_s2.png\" style=\"float: left; margin-right: 10px;\" width = 800 />"
      ]
    },
    {
      "metadata": {
        "id": "3O2zpquQm99m",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Visualizing the data\n",
        "for filename in img_files[:3]:\n",
        "    img=mpimg.imread(filename)\n",
        "    plt.figure(figsize=(10,10))\n",
        "    plt.imshow(img, cmap ='gray')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "gThb4p1RnP2R",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Label Encode writer names for one hot encoding later\n",
        "encoder = LabelEncoder()\n",
        "encoder.fit(img_targets)\n",
        "encoded_Y = encoder.transform(img_targets)\n",
        "\n",
        "print(img_files[:5], img_targets[:5], encoded_Y[:5])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "VaPAV068ncIi",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#split into test train and validation in ratio 4:1:1\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "train_files, rem_files, train_targets, rem_targets = train_test_split(\n",
        "        img_files, encoded_Y, train_size=0.66, random_state=52, shuffle= True)\n",
        "\n",
        "validation_files, test_files, validation_targets, test_targets = train_test_split(\n",
        "        rem_files, rem_targets, train_size=0.5, random_state=22, shuffle=True)\n",
        "\n",
        "print(train_files.shape, validation_files.shape, test_files.shape)\n",
        "print(train_targets.shape, validation_targets.shape, test_targets.shape)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Vzbq9OnWnkdU",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Input to the model\n",
        "As suggested in the paper, the input to the model are not unique sentences but rather random patches cropped from each sentence. This was done by:\n",
        "\n",
        "Resizing each sentence so that new height is 113 pixels and new width is such that original aspect ratio is maintained\n",
        "As stated in the paper, distorting the shape of image by changing the aspect ratio resulted in a big drop in model performance\n",
        "From the adjusted image, patches of 113x113 are randomly cropped\n",
        "Pic below shows the random 113x113 patches from one of the sentences combined in one frame\n",
        "\n",
        "Collage of 8 113x113 patches: <img src='markdown_pics/combined.jpeg' width=200>"
      ]
    },
    {
      "metadata": {
        "id": "Vk31TSWwnjq-",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# # Now create generators for randomly cropping 113x113 patches from these images\n",
        "\n",
        "batch_size = 16\n",
        "num_classes = 50\n",
        "\n",
        "# Start with train generator shared in the class and add image augmentations\n",
        "def generate_data(samples, target_files,  batch_size=batch_size, factor = 0.1 ):\n",
        "    num_samples = len(samples)\n",
        "    from sklearn.utils import shuffle\n",
        "    while 1: # Loop forever so the generator never terminates\n",
        "        for offset in range(0, num_samples, batch_size):\n",
        "            batch_samples = samples[offset:offset+batch_size]\n",
        "            batch_targets = target_files[offset:offset+batch_size]\n",
        "\n",
        "            images = []\n",
        "            targets = []\n",
        "            for i in range(len(batch_samples)):\n",
        "                batch_sample = batch_samples[i]\n",
        "                batch_target = batch_targets[i]\n",
        "                im = Image.open(batch_sample)\n",
        "                cur_width = im.size[0]\n",
        "                cur_height = im.size[1]\n",
        "\n",
        "                # print(cur_width, cur_height)\n",
        "                height_fac = 113 / cur_height\n",
        "\n",
        "                new_width = int(cur_width * height_fac)\n",
        "                size = new_width, 113\n",
        "\n",
        "                imresize = im.resize((size), Image.ANTIALIAS)  # Resize so height = 113 while keeping aspect ratio\n",
        "                now_width = imresize.size[0]\n",
        "                now_height = imresize.size[1]\n",
        "                # Generate crops of size 113x113 from this resized image and keep random 10% of crops\n",
        "\n",
        "                avail_x_points = list(range(0, now_width - 113 ))# total x start points are from 0 to width -113\n",
        "\n",
        "                # Pick random x%\n",
        "                pick_num = int(len(avail_x_points)*factor)\n",
        "\n",
        "                # Now pick\n",
        "                random_startx = sample(avail_x_points,  pick_num)\n",
        "\n",
        "                for start in random_startx:\n",
        "                    imcrop = imresize.crop((start, 0, start+113, 113))\n",
        "                    images.append(np.asarray(imcrop))\n",
        "                    targets.append(batch_target)\n",
        "                    \n",
        "                    \n",
        "         # trim image to only see section with road\n",
        "            X_train = np.array(images)\n",
        "            y_train = np.array(targets)\n",
        "\n",
        "            #reshape X_train for feeding in later\n",
        "            X_train = X_train.reshape(X_train.shape[0], 113, 113, 1)\n",
        "            #convert to float and normalize\n",
        "            X_train = X_train.astype('float32')\n",
        "            X_train /= 255\n",
        "\n",
        "            #One hot encode y\n",
        "            y_train = to_categorical(y_train, num_classes)\n",
        "\n",
        "            yield shuffle(X_train, y_train)               "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "acVH5lUcoOWC",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Generate data for training and validation\n",
        "train_generator = generate_data(train_files, train_targets, batch_size=batch_size, factor = 0.3)\n",
        "validation_generator = generate_data(validation_files, validation_targets, batch_size=batch_size, factor = 0.3)\n",
        "test_generator = generate_data(test_files, test_targets, batch_size=batch_size, factor = 0.1)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "pFZ4VjENoT50",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Build a neural network in Keras\n",
        "\n",
        "# Function to resize image to 56x56\n",
        "def resize_image(image):\n",
        "    import tensorflow as tf\n",
        "    return tf.image.resize_images(image,[56,56])\n",
        "\n",
        "# Function to resize image to 64x64\n",
        "row, col, ch = 113, 113, 1\n",
        "\n",
        "model = Sequential()\n",
        "model.add(ZeroPadding2D((1, 1), input_shape=(row, col, ch)))\n",
        "\n",
        "# Resise data within the neural network\n",
        "model.add(Lambda(resize_image))  #resize images to allow for easy computation\n",
        "\n",
        "# CNN model - Building the model suggested in paper\n",
        "\n",
        "model.add(Convolution2D(filters= 32, kernel_size =(5,5), strides= (2,2), padding='same', name='conv1')) #96\n",
        "model.add(Activation('relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2,2),strides=(2,2), name='pool1'))\n",
        "\n",
        "model.add(Convolution2D(filters= 64, kernel_size =(3,3), strides= (1,1), padding='same', name='conv2'))  #256\n",
        "model.add(Activation('relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2,2),strides=(2,2), name='pool2'))\n",
        "\n",
        "model.add(Convolution2D(filters= 128, kernel_size =(3,3), strides= (1,1), padding='same', name='conv3'))  #256\n",
        "model.add(Activation('relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2,2),strides=(2,2), name='pool3'))\n",
        "\n",
        "model.add(Flatten())\n",
        "model.add(Dropout(0.5))\n",
        "\n",
        "model.add(Dense(512, name='dense1'))  #1024\n",
        "# model.add(BatchNormalization())\n",
        "model.add(Activation('relu'))\n",
        "model.add(Dropout(0.5))\n",
        "\n",
        "model.add(Dense(256, name='dense2'))  #1024\n",
        "model.add(Activation('relu'))\n",
        "model.add(Dropout(0.5))\n",
        "\n",
        "model.add(Dense(num_classes,name='output'))\n",
        "model.add(Activation('softmax'))  #softmax since output is within 50 classes\n",
        "\n",
        "model.compile(loss='categorical_crossentropy', optimizer=Adam(), metrics=['accuracy'])\n",
        "print(model.summary())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "AtbPg78uo4FJ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Train the model \n",
        "\n",
        "nb_epoch = 8\n",
        "\n",
        "samples_per_epoch = 3268\n",
        "nb_val_samples = 842\n",
        "\n",
        "\n",
        "#save every model using Keras checkpoint\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "filepath=\"checkpoint2/check-{epoch:02d}-{val_loss:.4f}.hdf5\"\n",
        "checkpoint = ModelCheckpoint(filepath= filepath, verbose=1, save_best_only=False)\n",
        "callbacks_list = [checkpoint]\n",
        "\n",
        "#Model fit generator\n",
        "history_object = model.fit_generator(train_generator, samples_per_epoch= samples_per_epoch,\n",
        "                                     validation_data=validation_generator,\n",
        "                                     nb_val_samples=nb_val_samples, nb_epoch=nb_epoch, verbose=1, callbacks=callbacks_list)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "1-_SqY7fpECJ",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**Test model performance on the Test Set**\n",
        "\n",
        "-Accuracy on test set\n",
        "\n",
        "-Samples predicted to be from the same writer"
      ]
    },
    {
      "metadata": {
        "id": "4yioOnf6pLyu",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Load save model and use for prediction on test set\n",
        "model.load_weights('low_loss.hdf5')\n",
        "scores = model.evaluate_generator(test_generator,842) \n",
        "print(\"Accuracy = \", scores[1])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "2tEznmRHpiEB",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "images = []\n",
        "for filename in test_files[:50]:\n",
        "    im = Image.open(filename)\n",
        "    cur_width = im.size[0]\n",
        "    cur_height = im.size[1]\n",
        "\n",
        "    # print(cur_width, cur_height)\n",
        "    height_fac = 113 / cur_height\n",
        "\n",
        "    new_width = int(cur_width * height_fac)\n",
        "    size = new_width, 113\n",
        "\n",
        "    imresize = im.resize((size), Image.ANTIALIAS)  # Resize so height = 113 while keeping aspect ratio\n",
        "    now_width = imresize.size[0]\n",
        "    now_height = imresize.size[1]\n",
        "    # Generate crops of size 113x113 from this resized image and keep random 10% of crops\n",
        "\n",
        "    avail_x_points = list(range(0, now_width - 113 ))# total x start points are from 0 to width -113\n",
        "\n",
        "    # Pick random x%\n",
        "    factor = 0.1\n",
        "    pick_num = int(len(avail_x_points)*factor)\n",
        "    \n",
        "    random_startx = sample(avail_x_points,  pick_num)\n",
        "\n",
        "    for start in random_startx:\n",
        "        imcrop = imresize.crop((start, 0, start+113, 113))\n",
        "        images.append(np.asarray(imcrop))\n",
        "        \n",
        "    X_test = np.array(images)\n",
        "    \n",
        "    X_test = X_test.reshape(X_test.shape[0], 113, 113, 1)\n",
        "    #convert to float and normalize\n",
        "    X_test = X_test.astype('float32')\n",
        "    X_test /= 255\n",
        "    shuffle(X_test)\n",
        "\n",
        "print(X_test.shape)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "CGlNYB-npj5u",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Play with results from model \n",
        "predictions = model.predict(X_test, verbose =1)\n",
        "\n",
        "print(predictions.shape)\n",
        "predicted_writer = []\n",
        "for pred in predictions:\n",
        "    predicted_writer.append(np.argmax(pred))\n",
        "print(len(predicted_writer))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "dSGUWq_WpsJp",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "writer_number = 18\n",
        "total_images =10\n",
        "counter = 0\n",
        "for i in range(len(predicted_writer)//10):\n",
        "    if predicted_writer[i] == writer_number:\n",
        "        image = X_test[i].squeeze()\n",
        "        plt.figure(figsize=(2,2))\n",
        "        plt.imshow(image, cmap ='gray')"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}